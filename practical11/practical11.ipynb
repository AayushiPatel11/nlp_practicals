{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled5.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "h-H6u1E26BiN"
      },
      "source": [
        "import nltk\n",
        "from nltk.corpus import brown"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I-LPP2Gn6KPB",
        "outputId": "a8a4fabd-8f36-483d-ea2c-fd4ad5eab5c5"
      },
      "source": [
        "nltk.download('brown')\n",
        "brown.tagged_sents()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/brown.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[('The', 'AT'), ('Fulton', 'NP-TL'), ('County', 'NN-TL'), ('Grand', 'JJ-TL'), ('Jury', 'NN-TL'), ('said', 'VBD'), ('Friday', 'NR'), ('an', 'AT'), ('investigation', 'NN'), ('of', 'IN'), (\"Atlanta's\", 'NP$'), ('recent', 'JJ'), ('primary', 'NN'), ('election', 'NN'), ('produced', 'VBD'), ('``', '``'), ('no', 'AT'), ('evidence', 'NN'), (\"''\", \"''\"), ('that', 'CS'), ('any', 'DTI'), ('irregularities', 'NNS'), ('took', 'VBD'), ('place', 'NN'), ('.', '.')], [('The', 'AT'), ('jury', 'NN'), ('further', 'RBR'), ('said', 'VBD'), ('in', 'IN'), ('term-end', 'NN'), ('presentments', 'NNS'), ('that', 'CS'), ('the', 'AT'), ('City', 'NN-TL'), ('Executive', 'JJ-TL'), ('Committee', 'NN-TL'), (',', ','), ('which', 'WDT'), ('had', 'HVD'), ('over-all', 'JJ'), ('charge', 'NN'), ('of', 'IN'), ('the', 'AT'), ('election', 'NN'), (',', ','), ('``', '``'), ('deserves', 'VBZ'), ('the', 'AT'), ('praise', 'NN'), ('and', 'CC'), ('thanks', 'NNS'), ('of', 'IN'), ('the', 'AT'), ('City', 'NN-TL'), ('of', 'IN-TL'), ('Atlanta', 'NP-TL'), (\"''\", \"''\"), ('for', 'IN'), ('the', 'AT'), ('manner', 'NN'), ('in', 'IN'), ('which', 'WDT'), ('the', 'AT'), ('election', 'NN'), ('was', 'BEDZ'), ('conducted', 'VBN'), ('.', '.')], ...]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EgSH2Xvc6MxI"
      },
      "source": [
        "# list of all the unique tags from the corpus\n",
        "\n",
        "brown_word_tags=[]\n",
        "\n",
        "#Manually adding the start and the end tag\n",
        "for brown_sent in brown.tagged_sents():\n",
        "    brown_word_tags.append(('START','START'))\n",
        "    \n",
        "    for words,tag in brown_sent:\n",
        "        brown_word_tags.extend([(tag[:2],words)])\n",
        "        \n",
        "    brown_word_tags.append(('END','END'))"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6_OGyf506b7y"
      },
      "source": [
        "#Getting the continuous frequency distribution for the words which are tagged\n",
        "cfd_tag_words=nltk.ConditionalFreqDist(brown_word_tags)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WwsxcDf46cG5"
      },
      "source": [
        "#Getting the conditional probability distribution\n",
        "cpd_tag_words=nltk.ConditionalProbDist(cfd_tag_words,nltk.MLEProbDist)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uORZBe4Y6hJx",
        "outputId": "d4bbad31-0ba8-42cb-f729-438eb5582ecb"
      },
      "source": [
        "print(\"The probability of an adjective (JJ) being 'smart' is\", cpd_tag_words[\"JJ\"].prob(\"smart\"))\n",
        "print(\"The probability of a verb (VB) being 'try' is\", cpd_tag_words[\"VB\"].prob(\"try\"))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The probability of an adjective (JJ) being 'smart' is 0.00027780092785509904\n",
            "The probability of a verb (VB) being 'try' is 0.0010790559555256297\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ri4F30co6hMb"
      },
      "source": [
        "brown_tags=[]\n",
        "for tag, words in brown_word_tags:\n",
        "    brown_tags.append(tag)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CVpa9BvK6hP6"
      },
      "source": [
        "#make conditional frequency distribution: count(t{i-1} ti)\n",
        "cfd_tags=nltk.ConditionalFreqDist(nltk.bigrams(brown_tags))"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SAsNZMXK6p-z"
      },
      "source": [
        "# make conditional probability distribution, using maximum likelihood estimate: P(ti | t{i-1})\n",
        "cpd_tags=nltk.ConditionalProbDist(cfd_tags,nltk.MLEProbDist)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l2cQo-C16qCQ",
        "outputId": "c7610544-8134-4204-ce70-530323645f8f"
      },
      "source": [
        "print('The probability of DT occuring after NN is : ', cpd_tags[\"NN\"].prob(\"DT\"))\n",
        "print('The probability of VB occuring after NN is : ', cpd_tags[\"NN\"].prob(\"VB\"))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The probability of DT occuring after NN is :  0.0018349509874933604\n",
            "The probability of VB occuring after NN is :  0.0646359290427087\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WIvB4iyx6yT4"
      },
      "source": [
        "Implementation of Viterbi algorithm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a9VKbF-Q61Pl"
      },
      "source": [
        "distinct_brown_tags=set(brown_tags)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "atYWdeDV614u"
      },
      "source": [
        "sample_sentences=[\"I\",\"love\",\"spicy\",\"food\"]\n",
        "len_sample_sentence=len(sample_sentences)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2NeAQN7n617R"
      },
      "source": [
        "viterbi_tags={}\n",
        "viterbi_backpointer={}\n",
        "\n",
        "for tag in distinct_brown_tags:\n",
        "    if tag==\"START\":\n",
        "        continue\n",
        "    viterbi_tags[tag]=cpd_tags[\"START\"].prob(tag)*cpd_tag_words[tag].prob(sample_sentences[0])\n",
        "    viterbi_backpointer[tag]=\"START\""
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LbYW2wl0619v"
      },
      "source": [
        "# for each step i in 1 .. sentlen,\n",
        "# store a dictionary\n",
        "# that maps each tag X\n",
        "# to the probability of the best tag sequence of length i that ends in X\n",
        "\n",
        "\n",
        "\n",
        "viterbi_main=[]\n",
        "backpointer_main=[]\n",
        "\n",
        "viterbi_main.append(viterbi_tags)\n",
        "backpointer_main.append(viterbi_backpointer)\n",
        "\n",
        "current_best=max(viterbi_tags.keys(),key=lambda tag: viterbi_tags[tag])"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MVJ319xf62Aa",
        "outputId": "7816e2b8-71af-4525-ae29-b3404dfcfda4"
      },
      "source": [
        "print(\"Word\", \"'\" + sample_sentences[0] + \"'\", \"current best two-tag sequence:\", viterbi_backpointer[current_best], current_best)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word 'I' current best two-tag sequence: START PP\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fKwNtdFG62DE",
        "outputId": "189cf2de-6bc9-427f-c070-dc550322a0fc"
      },
      "source": [
        "for index in range(1,len_sample_sentence):\n",
        "    curr_viterbi={}\n",
        "    curr_backpointer={}\n",
        "    prev_viterbi=viterbi_main[-1]\n",
        "    \n",
        "    for brown_tag in distinct_brown_tags:\n",
        "        \n",
        "        if brown_tag != \"START\":\n",
        "            # if this tag is X and the current word is w, then\n",
        "            # find the previous tag Y such that\n",
        "            # the best tag sequence that ends in X\n",
        "            # actually ends in Y X\n",
        "            # that is, the Y that maximizes\n",
        "            # prev_viterbi[ Y ] * P(X | Y) * P( w | X)\n",
        "            # The following command has the same notation\n",
        "            # that you saw in the sorted() command.\n",
        "            prev_best = max(prev_viterbi.keys(),\n",
        "                                key=lambda prevtag: \\\n",
        "                                    prev_viterbi[prevtag] * cpd_tags[prevtag].prob(brown_tag) * cpd_tag_words[brown_tag].prob(\n",
        "                                        sample_sentences[index]))\n",
        "\n",
        "            curr_viterbi[brown_tag] = prev_viterbi[prev_best] * \\\n",
        "                                cpd_tags[prev_best].prob(brown_tag) * cpd_tag_words[brown_tag].prob(sample_sentences[index])\n",
        "            curr_backpointer[brown_tag] = prev_best\n",
        "\n",
        "    current_best = max(curr_viterbi.keys(), key=lambda tag: curr_viterbi[tag])\n",
        "    print(\"Word\", \"'\" + sample_sentences[index] + \"'\", \"current best two-tag sequence:\", curr_backpointer[current_best], current_best)\n",
        "\n",
        "\n",
        "    viterbi_main.append(curr_viterbi)\n",
        "    backpointer_main.append(curr_backpointer)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word 'love' current best two-tag sequence: PP NN\n",
            "Word 'spicy' current best two-tag sequence: VB JJ\n",
            "Word 'food' current best two-tag sequence: JJ NN\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ks6oVjZW62GI"
      },
      "source": [
        "# now find the probability of each tag\n",
        "# to have \"END\" as the next tag,\n",
        "# and use that to find the overall best sequence\n",
        "\n",
        "\n",
        "\n",
        "prev_viterbi = viterbi_main[-1]\n",
        "prev_best = max(prev_viterbi.keys(),\n",
        "                    key=lambda prev_tag: prev_viterbi[prev_tag] * cpd_tags[prev_tag].prob(\"END\"))\n",
        "\n",
        "prob_tag_sequence = prev_viterbi[prev_best] * cpd_tags[prev_best].prob(\"END\")\n",
        "\n",
        "\n",
        "best_tag_sequence = [\"END\", prev_best]\n",
        "# invert the list of backpointers\n",
        "backpointer_main.reverse()\n",
        "\n",
        "# go backwards through the list of backpointers\n",
        "# (or in this case forward, because we have inverter the backpointer list)\n",
        "# in each case:\n",
        "# the following best tag is the one listed under\n",
        "# the backpointer for the current best tag\n",
        "current_best_tag = prev_best\n",
        "for backpointer in backpointer_main:\n",
        "    best_tag_sequence.append(backpointer[current_best_tag])\n",
        "    current_best_tag = backpointer[current_best_tag]"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Izk8GtXA7JSB"
      },
      "source": [
        "best_tag_sequence.reverse()"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "To4wmmVW7JU2",
        "outputId": "d7d18988-e758-47f6-b8f2-e8249aeedc73"
      },
      "source": [
        "print(\"The sentence given is :\")\n",
        "for word in sample_sentences:\n",
        "    print (word,\"\",)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The sentence given is :\n",
            "I \n",
            "love \n",
            "spicy \n",
            "food \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3apihuEj7JXv",
        "outputId": "4bf845d0-3fb9-40a2-8938-8d9394f6d6e3"
      },
      "source": [
        "print(\"The best tag sequence using HMM for the given sentence is : \")\n",
        "\n",
        "\n",
        "for best_tag in best_tag_sequence:\n",
        "    print (best_tag, \"\",)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The best tag sequence using HMM for the given sentence is : \n",
            "START \n",
            "PP \n",
            "VB \n",
            "JJ \n",
            "NN \n",
            "END \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8W9DptFW7Jan"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XNacEhip7JeO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zJKAw1sY62Ji"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}